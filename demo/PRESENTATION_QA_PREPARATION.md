# 발표 Q&A 대비 가이드
## 예상 질문과 답변 준비

---

## 🎯 핵심 질문 카테고리

### 1. 기술적 질문

#### Q: "어떤 ML 모델을 사용하나요?"
**답변:**
> "Random Forest 회귀 모델을 사용합니다. 각 성격 특성(Logic, Intuition, Fluidity, Complexity)별로 
> 독립적인 모델을 학습시켰으며, 4차원 특징 벡터(의사결정 지연시간, 수정 빈도, 경로 효율성, 상호작용 강도)를 입력받아 
> 성격 가중치를 예측합니다. 
> 
> 현재는 합성 데이터로 사전 학습했지만, 실제 사용자 데이터가 축적되면 
> 온라인 학습 기능을 통해 지속적으로 개선할 수 있습니다."

**보여줄 것:**
- ML 모델 코드 스니펫
- 예측 결과 예시
- 특징 중요도

---

#### Q: "데이터는 어떻게 수집하나요?"
**답변:**
> "프론트엔드의 BehaviorTracker가 사용자의 마우스 움직임, 클릭, 의사결정 시간 등을 
> 실시간으로 수집합니다. 이 데이터는 백엔드 API로 전송되어 처리되며, 
> 실제 데이터베이스에 저장됩니다. 
> 
> 현재 실제 데이터베이스에 3명의 사용자와 12개의 세션이 저장되어 있으며, 
> 행동 프로필과 성격 가중치가 계산되어 있습니다."

**보여줄 것:**
- BehaviorTracker 코드
- 데이터베이스 통계
- 실제 세션 데이터 예시

---

#### Q: "정확도는 얼마나 되나요?"
**답변:**
> "현재는 합성 데이터와 제한된 실제 데이터로 검증했습니다. 
> 시연 결과를 보면 신뢰도가 세션 1에서 30%로 시작해 세션 7에서 82%까지 증가했습니다. 
> 이는 지속적 학습 알고리즘(EMA)이 작동하고 있음을 보여줍니다. 
> 
> 실제 정확도는 더 많은 실제 사용자 데이터로 검증이 필요하며, 
> 현재는 개념 검증(Proof of Concept) 단계입니다. 
> 실제 서비스로 확장하면 대규모 데이터로 모델을 재학습하여 성능을 개선할 수 있습니다."

**보여줄 것:**
- 신뢰도 증가 차트
- 세션별 데이터
- 향후 개선 계획

---

### 2. 실용성 질문

#### Q: "실제로 사용할 수 있나요?"
**답변:**
> "현재는 프로토타입 단계입니다. 핵심 AI/ML 로직은 실제로 작동하며, 
> 실제 데이터베이스에 데이터가 저장됩니다. 
> 
> 하지만 프로덕션 배포를 위해서는 인증 시스템, 모니터링, 보안 강화 등 
> 추가 작업이 필요합니다. 
> 
> 단계적으로는:
> - **현재**: 연구/프로토타입용으로 사용 가능
> - **1-2개월 후**: 베타 서비스 준비 가능 (인증, 모니터링 추가)
> - **3-6개월 후**: 프로덕션 배포 가능
> 
> 핵심은 실제 작동하는 시스템이라는 점입니다."

**보여줄 것:**
- 오프라인 시연 결과
- 실제 데이터베이스
- 향후 로드맵

---

#### Q: "실제 사용자로 테스트했나요?"
**답변:**
> "네, 실제 데이터베이스에 3명의 사용자 데이터가 있습니다. 
> 총 12개의 세션이 저장되어 있으며, 성격 가중치와 신뢰도가 계산되어 있습니다. 
> 
> 다만, 행동 프로필 데이터(의사결정 지연시간, 경로 효율성 등)는 
> 아직 충분히 수집되지 않아서, 시연용으로는 논리적으로 일관된 
> 샘플 데이터를 사용했습니다. 
> 
> 실제 서비스로 확장하면 더 많은 실제 데이터를 수집하여 
> 모델을 개선할 수 있습니다."

**보여줄 것:**
- 실제 데이터베이스 통계
- 실제 사용자 세션 예시
- 데이터 수집 개선 계획

---

### 3. 한계점 질문

#### Q: "프로덕션에 바로 적용 가능한가요?"
**답변:**
> "현재는 프로토타입 단계입니다. 핵심 AI/ML 로직은 실제로 작동하지만, 
> 프로덕션 배포를 위해서는 다음이 필요합니다:
> 
> 1. **인증/보안 시스템**: JWT 기반 인증, 세션 관리
> 2. **모니터링**: 에러 추적, 성능 모니터링
> 3. **테스트 커버리지**: 현재 50% → 목표 70%+
> 4. **확장성**: SQLite → PostgreSQL 마이그레이션
> 
> 예상 작업 시간은 1-2개월(베타) ~ 3-6개월(프로덕션)입니다. 
> 핵심은 실제 작동하는 시스템이라는 점입니다."

**보여줄 것:**
- 프로덕션 준비도 체크리스트
- 향후 작업 계획
- 단계별 로드맵

---

#### Q: "성능이 검증되었나요?"
**답변:**
> "기본 성능은 검증했습니다. API 응답 시간은 목표인 200ms 이하를 달성했으며, 
> ML 모델 예측도 즉시 수행됩니다. 
> 
> 다만, 대규모 사용자와 다양한 시나리오에 대한 성능 검증은 
> 실제 서비스 확장 시 진행할 예정입니다. 
> 
> 현재는 개념 검증 단계이며, 실제 데이터가 축적되면 
> 모델 성능을 지속적으로 개선할 수 있습니다."

**보여줄 것:**
- 성능 메트릭
- 응답 시간 측정 결과
- 향후 성능 테스트 계획

---

### 4. 혁신성 질문

#### Q: "기존 시스템과 차이점은?"
**답변:**
> "기존의 명시적 설문지 기반 성격 평가와 달리, 
> 우리는 **암묵적 행동 신호**를 사용합니다. 
> 사용자가 직접 답변하지 않아도, 마우스 움직임, 의사결정 시간 등으로 
> 성격을 추론합니다. 
> 
> 또한 **머신러닝 기반 지속적 학습**을 통해 세션이 진행될수록 
> 더 정확한 프로필을 생성하며, **문화적 편향 완화** 기능도 포함되어 있습니다. 
> 
> 이는 디지털 휴먼 트윈이 사용자를 더 자연스럽게 이해할 수 있게 합니다."

**보여줄 것:**
- 기존 방식 vs 우리 방식 비교
- 지속적 학습 차트
- 문화적 편향 완화 예시

---

#### Q: "실제로 정확한가요?"
**답변:**
> "현재는 프로토타입 단계이므로 대규모 검증은 아직 진행하지 않았습니다. 
> 하지만 논리적으로 일관된 결과를 보여주며, 실제 사용자 데이터로도 
> 유사한 패턴을 확인했습니다. 
> 
> 정확도 향상을 위해서는:
> 1. 더 많은 실제 사용자 데이터 수집
> 2. 모델 재학습 및 하이퍼파라미터 튜닝
> 3. 교차 검증 및 A/B 테스트
> 
> 실제 서비스로 확장하면 이러한 과정을 통해 지속적으로 개선할 수 있습니다."

**보여줄 것:**
- 논리적 일관성 예시
- 실제 데이터 패턴
- 향후 검증 계획

---

## 🎤 발표 시나리오별 대응

### 시나리오 1: 기술에 관심 있는 심사위원

**강조할 점:**
- ML 모델 구조 (Random Forest)
- 특징 엔지니어링
- 지속적 학습 알고리즘 (EMA)
- 문화적 편향 완화

**보여줄 것:**
- 코드 스니펫
- 알고리즘 설명
- 수식 및 공식

---

### 시나리오 2: 실용성에 관심 있는 심사위원

**강조할 점:**
- 실제 작동하는 시스템
- 실제 데이터베이스
- 단계적 확장 계획
- 실용적 가치

**보여줄 것:**
- 오프라인 시연
- 실제 데이터 통계
- 향후 로드맵

---

### 시나리오 3: 혁신성에 관심 있는 심사위원

**강조할 점:**
- 암묵적 행동 분석
- 머신러닝 기반 접근
- 지속적 학습
- 디지털 휴먼 트윈 개념

**보여줄 것:**
- 개념 다이어그램
- 혁신적 접근 설명
- 향후 연구 방향

---

## 💡 답변 전략

### 1. 솔직하게 답변
- ✅ 작동하는 부분: 명확히 강조
- ⚠️ 한계점: 솔직하게 언급
- 🚀 향후 계획: 구체적으로 제시

### 2. 증거 제시
- ✅ 실제 시연 결과
- ✅ 실제 데이터베이스
- ✅ 코드 및 알고리즘

### 3. 긍정적 프레이밍
- ❌ "아직 구현되지 않았습니다"
- ✅ "프로토타입 단계이며, 핵심 로직은 작동합니다"
- ✅ "향후 1-2개월 내 구현 예정입니다"

---

## 📋 Q&A 체크리스트

### 준비 사항
- [ ] 오프라인 시연 준비
- [ ] 실제 데이터베이스 확인
- [ ] 차트 이미지 준비
- [ ] 코드 스니펫 준비
- [ ] 예상 질문 리스트

### 답변 원칙
- [ ] 솔직하게 답변
- [ ] 증거 제시
- [ ] 긍정적 프레이밍
- [ ] 시간 관리
- [ ] 핵심 메시지 유지

---

**© 2026 Nexus Entertainment**
